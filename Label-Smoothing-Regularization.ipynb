{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.optim as optim \n",
    "import torchvision \n",
    "import torchvision.transforms as transforms \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from skorch import NeuralNetClassifier \n",
    "from time import time \n",
    "from tqdm import tqdm \n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26.4M/26.4M [00:09<00:00, 2.76MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29.5k/29.5k [00:00<00:00, 160kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4.42M/4.42M [00:03<00:00, 1.17MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5.15k/5.15k [00:00<00:00, 5.58MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5), (0.5))])\n",
    "\n",
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=transform, download=True)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "batch_size = 64 \n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x278e61e7c10>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(20)\n",
    "torch.manual_seed(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x1 = torch.relu(self.fc1(x))\n",
    "        x2 = torch.relu(self.fc2(x1))\n",
    "        x3 = torch.relu(self.fc3(x2))\n",
    "        x4 = self.fc4(x3)\n",
    "\n",
    "        return x1,x2, x3, x4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model):\n",
    "    model.eval() \n",
    "    correct = 0 \n",
    "    total = 0 \n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data \n",
    "            outputs = model(inputs)[-1]\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return correct / total "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.5, Accuracy: 84.34%\n",
      "Epoch 2, Loss: 0.37, Accuracy: 85.70%\n",
      "Epoch 3, Loss: 0.33, Accuracy: 86.47%\n",
      "Epoch 4, Loss: 0.31, Accuracy: 87.80%\n",
      "Epoch 5, Loss: 0.29, Accuracy: 87.84%\n",
      "Epoch 6, Loss: 0.27, Accuracy: 87.40%\n",
      "Epoch 7, Loss: 0.26, Accuracy: 88.07%\n",
      "Epoch 8, Loss: 0.24, Accuracy: 88.06%\n",
      "Epoch 9, Loss: 0.23, Accuracy: 88.23%\n",
      "Epoch 10, Loss: 0.22, Accuracy: 87.73%\n",
      "Epoch 11, Loss: 0.21, Accuracy: 88.35%\n",
      "Epoch 12, Loss: 0.2, Accuracy: 88.80%\n",
      "Epoch 13, Loss: 0.19, Accuracy: 88.47%\n",
      "Epoch 14, Loss: 0.18, Accuracy: 88.64%\n",
      "Epoch 15, Loss: 0.17, Accuracy: 89.21%\n",
      "Epoch 16, Loss: 0.17, Accuracy: 88.55%\n",
      "Epoch 17, Loss: 0.16, Accuracy: 89.28%\n",
      "Epoch 18, Loss: 0.15, Accuracy: 88.63%\n",
      "Epoch 19, Loss: 0.14, Accuracy: 88.82%\n",
      "Epoch 20, Loss: 0.14, Accuracy: 89.61%\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNet()\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    net.train() \n",
    "    running_loss = 0.0 \n",
    "\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data \n",
    "        optimizer.zero_grad() \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs[-1], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    accuracy = evaluate(net) \n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {round(running_loss / len(trainloader), 2)}, Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ungdu\\AppData\\Local\\Temp\\ipykernel_8132\\1345615224.py:6: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(net(inputs[0])[-1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[3.0038e-03, 2.2447e-06, 1.0279e-03, 9.8587e-01, 2.0068e-06, 8.4903e-10,\n",
       "         1.0092e-02, 1.9513e-11, 6.8100e-07, 9.6484e-10]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data \n",
    "F.softmax(net(inputs[0])[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 1.19, Accruacy: 85.12%\n",
      "Epoch 2, Loss: 1.1, Accruacy: 86.00%\n",
      "Epoch 3, Loss: 1.08, Accruacy: 87.48%\n",
      "Epoch 4, Loss: 1.06, Accruacy: 86.97%\n",
      "Epoch 5, Loss: 1.05, Accruacy: 87.97%\n",
      "Epoch 6, Loss: 1.04, Accruacy: 86.90%\n",
      "Epoch 7, Loss: 1.03, Accruacy: 87.68%\n",
      "Epoch 8, Loss: 1.02, Accruacy: 88.91%\n",
      "Epoch 9, Loss: 1.01, Accruacy: 88.72%\n",
      "Epoch 10, Loss: 1.01, Accruacy: 88.20%\n",
      "Epoch 11, Loss: 1.0, Accruacy: 88.54%\n",
      "Epoch 12, Loss: 0.99, Accruacy: 88.75%\n",
      "Epoch 13, Loss: 0.99, Accruacy: 88.76%\n",
      "Epoch 14, Loss: 0.98, Accruacy: 88.30%\n",
      "Epoch 15, Loss: 0.98, Accruacy: 88.97%\n",
      "Epoch 16, Loss: 0.97, Accruacy: 89.01%\n",
      "Epoch 17, Loss: 0.97, Accruacy: 89.27%\n",
      "Epoch 18, Loss: 0.96, Accruacy: 88.86%\n",
      "Epoch 19, Loss: 0.96, Accruacy: 89.19%\n",
      "Epoch 20, Loss: 0.96, Accruacy: 88.94%\n"
     ]
    }
   ],
   "source": [
    "net = SimpleNet() \n",
    "criterion = nn.CrossEntropyLoss(label_smoothing = 0.2)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(20):\n",
    "    net.train() \n",
    "    running_loss = 0.0 \n",
    "\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data \n",
    "        optimizer.zero_grad() \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs[-1], labels)\n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item()\n",
    "    accuracy = evaluate(net)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {round(running_loss / len(trainloader), 2)}, Accruacy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ungdu\\AppData\\Local\\Temp\\ipykernel_8132\\2356410437.py:7: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  F.softmax(net(inputs[0])[-1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0210, 0.0185, 0.0239, 0.8123, 0.0194, 0.0191, 0.0261, 0.0199, 0.0190,\n",
       "         0.0209]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.eval() \n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        inputs, labels = data \n",
    "\n",
    "F.softmax(net(inputs[0])[-1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
